week6
import numpy as np
x=np.array(([2,9],[1,5],[3,6]),dtype=float)
print(x)
y=np.array(([92],[86],[89]),dtype=float)

x=x/np.max(x,axis=0)
y=y/100


def sigmold(x):
  return (1/(1+np.exp(-x)))

def derivatives_sigmold(x):
  return x*(1-x)

n=1000


input_layer_neurons=2
hidden_layer_neurons=2
output_neurons=1

wh=np.random.uniform(size=(input_layer_neurons,hidden_layer_neurons))
bh=np.random.uniform(size=(1,hidden_layer_neurons))
wout=np.random.uniform(size=(hidden_layer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))

for i in range(n):
  a1=np.dot(x,wh)
  b=a1+bh
  hlayer_act=sigmold(b)
  out1=np.dot(hlayer_act,wout)
  out=out1+bout
  output=sigmold(out)
  res=(y-output)






print("Actual output: \n"+str(y))
print("Predicated output: \n",str(output))
print("Error: \n"+str(res))
--------------------------------------------------------------------------------------------------------------------------
week7
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

nltk.download('vader_lexicon')  # Download the VADER lexicon

def sentiment_analysis(text):
    sia = SentimentIntensityAnalyzer()
    sentiment_score = sia.polarity_scores(text)
    
    if sentiment_score['compound'] >= 0.05:
        return 'Positive'
    elif sentiment_score['compound'] <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

# Example usage
text = "I love spending time with my family."
sentiment = sentiment_analysis(text)
print(sentiment)
------------------------------------------------------------------------------------------------------------
week8
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files
uploaded=files.upload()
train=pd.read_csv("train.csv")
train.head()
test=pd.read_csv("test.csv")
test.head()

train.isnull().sum()

train['Gender'].fillna(train['Gender'].mode()[0],inplace=True)

train['Married'].fillna(train['Married'].mode()[0],inplace=True)

train['Dependents'].fillna(train['Dependents'].mode()[0],inplace=True)

train['Self_Employed'].fillna(train['Self_Employed'].mode()[0],inplace=True)

train['LoanAmount'].fillna(train['LoanAmount'].mode()[0],inplace=True)

train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mean(),inplace=True)

train['Credit_History'].fillna(train['Credit_History'].mean(),inplace=True)

train.isnull().sum()

X=train.drop('Loan_Status',1)
#X=train.drop('Loan_ID')
X=X.drop('Loan_ID',axis=1)
Y=train['Loan_Status']
X=pd.get_dummies(X)
print(X)
print(Y)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
clf=model.fit(X,Y)
df=pd.read_csv('test.csv')
print(df)

df['Gender'].fillna(df['Gender'].mode()[0],inplace=True)

df['Dependents'].fillna(df['Dependents'].mode()[0],inplace=True)

df['Self_Employed'].fillna(df['Self_Employed'].mode()[0],inplace=True)
df['LoanAmount'].fillna(df['LoanAmount'].mean(),inplace=True)
#df['Loan_Amount_Term'].fillna(df[Loan_Amount_Term].mean(),inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mean(),inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean(),inplace=True)
df.isnull().sum()

df=df.drop('Loan_ID',axis=1)
df=pd.get_dummies(df)
print(X)
print(df)
clf.predict(df)
------------------------------------------------------------------------------------------------------------------------------

week9

import pandas as pd
import numpy as np
from google.colab import files
uploaded=files.upload()
data=pd.read_csv('water_dataX.csv',encoding="ISO-8859-1")
data.fillna(0, inplace=True)
data.head()
#conversions
data['Temp']=pd.to_numeric(data['Temp'],errors='coerce')
data['D.O. (mg/l)']=pd.to_numeric(data['D.O. (mg/l)'],errors='coerce')
data['PH']=pd.to_numeric(data['PH'],errors='coerce')
data['B.O.D. (mg/l)']=pd.to_numeric(data['B.O.D. (mg/l)'],errors='coerce')
data['CONDUCTIVITY (µmhos/cm)']=pd.to_numeric(data['CONDUCTIVITY (µmhos/cm)'],errors='coerce')
data['NITRATENAN N+ NITRITENANN (mg/l)']=pd.to_numeric(data['NITRATENAN N+ NITRITENANN (mg/l)'],errors='coerce')
data['TOTAL COLIFORM (MPN/100ml)Mean']=pd.to_numeric(data['TOTAL COLIFORM (MPN/100ml)Mean'],errors='coerce')
data.dtypes
#initialization
start=2
end=1779
station=data.iloc [start:end ,0]
location=data.iloc [start:end ,1]
state=data.iloc [start:end ,2]
do= data.iloc [start:end ,4].astype(np.float64)
value=0
ph = data.iloc[ start:end,5]  
co = data.iloc [start:end ,6].astype(np.float64)   
  
year=data.iloc[start:end,11]
tc=data.iloc [2:end ,10].astype(np.float64)


bod = data.iloc [start:end ,7].astype(np.float64)
na= data.iloc [start:end ,8].astype(np.float64)
na.dtype
data=pd.concat([station,location,state,do,ph,co,bod,na,tc,year],axis=1)
data. columns = ['station','location','state','do','ph','co','bod','na','tc','year']
#calulation of Ph
data['npH']=data.ph.apply(lambda x: (100 if (8.5>=x>=7)  
                                 else(80 if  (8.6>=x>=8.5) or (6.9>=x>=6.8) 
                                      else(60 if (8.8>=x>=8.6) or (6.8>=x>=6.7) 
                                          else(40 if (9>=x>=8.8) or (6.7>=x>=6.5)
                                              else 0)))))
#calculation of dissolved oxygen
data['ndo']=data.do.apply(lambda x:(100 if (x>=6)  
                                 else(80 if  (6>=x>=5.1) 
                                      else(60 if (5>=x>=4.1)
                                          else(40 if (4>=x>=3) 
                                              else 0)))))
data['wph']=data.npH * 0.165
data['wdo']=data.ndo * 0.281

data['wqi']=data.wph+data.wdo
data
#scatter plot of data points
import matplotlib.pyplot as plt
cols =['year']
y = data['wqi']
x=data[cols]

plt.scatter(x,y)
plt.show()

----------------------------------------------------------------------------------------------------------
week10
import pandas as pd
from google.colab import files
uploaded = files.upload()
iplmatches=pd.read_csv("matches.csv")

iplmatches.isnull().sum()
iplmatches.drop(['umpire3'],axis=1,inplace=True)
teams_per_season = iplmatches.groupby('season')['winner'].value_counts()
teams_per_season
year = 2008
winteamseason = pd.DataFrame(columns=['year', 'team', 'wins'])
winteamseason
for items in teams_per_season.items():
    if items[0][0]==year:
        print(items)
        win_series = pd.DataFrame({ 'year': [items[0][0]], 'team': [items[0][1]], 'wins': [items[1]]})
        winteamseason = winteamseason.append(win_series)
        year += 1
print(winteamseason)


venue = iplmatches['venue'].value_counts()
print(venue)

plt.figure(figsize = (10,6))
sns.countplot(y = 'venue',data = iplmatches,order = iplmatches['venue'].value_counts().iloc[:10].index)
plt.xlabel('No of matches',fontsize=12)
plt.ylabel('Venue',fontsize=12)
plt.title('Total Number of matches played in different stadium')

plt.figure(figsize = (10,6))
sns.countplot(y = 'winner',data = iplmatches,order= iplmatches['winner'].value_counts().index)
plt.xlabel('Wins')
plt.title('Number of  IPL  matches won by each team')
